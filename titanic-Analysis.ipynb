{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "# LIMPIEZA DE DATOS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion de un diccionario donde se recogerán todos los cambios que se le harán al dataset inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\archivos\\titanic\\train.csv')\n",
    "hist_dataset = {'initial' : df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_NaN_dict(hist_dict, key):\n",
    "       \n",
    "    data_return =  hist_dict[key].isna().sum(axis=0) / len(hist_dict[key])\n",
    "    columns = hist_dataset[key].columns\n",
    "\n",
    "    print(\n",
    "        'Tamaño del dataset', \n",
    "        '\\n------------------', \n",
    "        f'\\n{hist_dataset[key].shape}'\n",
    "    )\n",
    "    print(\n",
    "        '\\nPorcentaje de valores nulos'\n",
    "        '\\n---------------------------'\n",
    "    )\n",
    "    i = 0\n",
    "    for column in columns:\n",
    "        if data_return[column] != .0:\n",
    "            print(f'{column:18} {data_return[column]:.6f}')\n",
    "            i = 1\n",
    "    if i == 0: print('- No hay elementos nulos -')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del dataset \n------------------ \n(891, 12)\n\nPorcentaje de valores nulos\n---------------------------\nAge                0.198653\nCabin              0.771044\nEmbarked           0.002245\n"
     ]
    }
   ],
   "source": [
    "p_NaN_dict(hist_dataset, 'initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de la calidad de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a la búsqueda de valores perdidos y a la eliminación de las variables (columnas) con un porcentage de valores NaN mayor al porporcionado por el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del dataset \n------------------ \n(891, 12)\n\nPorcentaje de valores nulos\n---------------------------\nAge                0.198653\nCabin              0.771044\nEmbarked           0.002245\n"
     ]
    }
   ],
   "source": [
    "p_NaN_dict(hist_dataset, 'initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_CNaN(\n",
    "    data,\n",
    "    columns = None, \n",
    "    p = 0.7, \n",
    "    hist_dataset = None):\n",
    "    \n",
    "    if columns == None: columns = data.columns\n",
    "        \n",
    "    df = data[columns]\n",
    "\n",
    "    serie = df.isna().sum(axis=0) / len(df)\n",
    "    columns_to_drop = [ column for column in serie.index if serie[column] > p ]\n",
    "    \n",
    "    data_return = data.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "    if hist_dataset != None: hist_dataset[ 'clean_CNaN' ] = data_return\n",
    "\n",
    "    return data_return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del dataset \n------------------ \n(891, 11)\n\nPorcentaje de valores nulos\n---------------------------\nAge                0.198653\nEmbarked           0.002245\n"
     ]
    }
   ],
   "source": [
    "df = hist_dataset['initial']\n",
    "columns = df.columns\n",
    "df = clean_CNaN(df, p = 0.6, hist_dataset = hist_dataset)\n",
    "p_NaN_dict(hist_dataset, 'clean_CNaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procede a la eliminación de las observaciones que contengan valores NaN en las colunmas que sean relevantes para posibles calculos o predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_NaN(\n",
    "    data, \n",
    "    columns = None,\n",
    "    hist_dataset = None):\n",
    "    \n",
    "    if columns == None: columns = data.columns\n",
    "\n",
    "    data_return = data.dropna(subset = columns)\n",
    "    #for column in columns:\n",
    "    #    data_return[column] = df[df.column.notna()]\n",
    "    \n",
    "    if hist_dataset != None: hist_dataset[ 'clean_NaN' ] = data_return\n",
    "\n",
    "    return data_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tamaño del dataset \n------------------ \n(714, 11)\n\nPorcentaje de valores nulos\n---------------------------\nEmbarked           0.002801\n"
     ]
    }
   ],
   "source": [
    "df = hist_dataset['clean_CNaN']\n",
    "df = clean_NaN(df, columns = ['Age'], hist_dataset = hist_dataset)\n",
    "p_NaN_dict(hist_dataset, 'clean_NaN')"
   ]
  },
  {
   "source": [
    "## Outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Eliminar los valores atímpicos, se entablecerá intervalo donde los datos se considerarán válidos. Se aplicará para todas las variables no categóricas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __RI__(serie):\n",
    "    Q1 = np.percentile(serie, q = 25)\n",
    "    Q3 = np.percentile(serie, q = 75)\n",
    "    R = Q3 - Q1\n",
    "    lim_inf = Q1 - 1.5*R\n",
    "    lim_sup = Q3 + 1.5*R\n",
    "\n",
    "    if serie.dtype == 'float64':\n",
    "        lim_inf = round(np.float64(lim_inf), 4)\n",
    "        lim_sup = round(np.float64(lim_sup), 4)\n",
    "    if serie.dtype == 'int64':\n",
    "        lim_inf = np.int64(round(lim_inf, 0))\n",
    "        lim_sup = np.int64(round(lim_sup, 0))\n",
    "\n",
    "    return lim_inf, lim_sup\n",
    "\n",
    "def clean_Outliers(\n",
    "    data,\n",
    "    columns = None,\n",
    "    hist_dataset = None):\n",
    "\n",
    "    if columns == None: columns = data.columns\n",
    "    df = data\n",
    "\n",
    "    for column in columns:\n",
    "        lim_inf, lim_sup = __RI__(df[column])\n",
    "\n",
    "        print('Intervalo de', column, ':', lim_inf, lim_sup)\n",
    "\n",
    "    print('')\n",
    "    \n",
    "    for column in columns:\n",
    "        for i in df[column].index:\n",
    "            if df[column][i] <= lim_inf or df[column][i] >= lim_sup:\n",
    "                df = df.drop([i], axis = 0)\n",
    "\n",
    "    data_return = df\n",
    "    if hist_dataset != None: hist_dataset['clean_Outliers'] = data_return\n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Intervalo de Age : -6.6875 64.8125\n",
      "Intervalo de SibSp : -2 2\n",
      "Intervalo de Parch : -2 2\n",
      "Intervalo de Fare : -29.9375 71.3625\n",
      "\n",
      "Tamaño del dataset \n",
      "------------------ \n",
      "(618, 11)\n",
      "\n",
      "Porcentaje de valores nulos\n",
      "---------------------------\n",
      "- No hay elementos nulos -\n"
     ]
    }
   ],
   "source": [
    "columns = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "df = hist_dataset['clean_NaN']\n",
    "df = clean_Outliers(df, columns = columns, hist_dataset = hist_dataset)\n",
    "p_NaN_dict(hist_dataset, 'clean_Outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['initial', 'clean_CNaN', 'clean_NaN', 'clean_Outliers'])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "hist_dataset.keys()"
   ]
  },
  {
   "source": [
    "## Variables **One Hot** o **Dummies**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Transformación de variables categóricas en variables dummies, con el objetivo de tener un mayor número de variables con las que entrenar nuestro modelo de predicción.\n",
    "\n",
    "Primero inspeccionamos los tipos de variables que tenemos y desechamos las que no nos servirán en nuestro modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500        S  \n",
       "1      0          PC 17599  71.2833        C  \n",
       "2      0  STON/O2. 3101282   7.9250        S  \n",
       "3      0            113803  53.1000        S  \n",
       "4      0            373450   8.0500        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "hist_dataset['clean_Outliers'].head()"
   ]
  },
  {
   "source": [
    "Eliminamos las variables que no dan valor a nuestro análisis y modelos. PassengerID, Name y Ticket son datos específicos a cada pasajero que no dan un valor estadístico."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_no_stats = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
    "hist_dataset['statistical-data'] = hist_dataset['clean_Outliers'].drop(v_no_stats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "hist_dataset['statistical-data'].head()"
   ]
  },
  {
   "source": [
    "Realizamos un conteo de los valores de cada columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    397\n1    221\nName: Survived, dtype: int64\n3    354\n2    168\n1     96\nName: Pclass, dtype: int64\nmale      413\nfemale    205\nName: Sex, dtype: int64\n0    425\n1    143\n2     18\n4     18\n3      9\n5      5\nName: SibSp, dtype: int64\n0    463\n1     91\n2     50\n3      5\n5      5\n4      3\n6      1\nName: Parch, dtype: int64\nS    505\nC     87\nQ     26\nName: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = hist_dataset['statistical-data']\n",
    "vars_disc = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch','Embarked']\n",
    "for i in vars_disc:\n",
    "    print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_dummy(\n",
    "    data,\n",
    "    columns = None,\n",
    "    hist_dataset = None):\n",
    "\n",
    "    if columns == None: columns = data.columns\n",
    "    df = data \n",
    "\n",
    "    for column in columns:\n",
    "        categorias = df[column].value_counts().index\n",
    "\n",
    "        for categoria in categorias:\n",
    "            name = str(column) + '-' + str(categoria)\n",
    "            df[name] = np.where(df[column] == categoria, 1, 0)\n",
    "\n",
    "        df = df.drop([column], axis = 1)\n",
    "    \n",
    "    data_return = df\n",
    "    if hist_dataset != None: hist_dataset['cat_to_dummy'] = data_return\n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hist_dataset['statistical-data']\n",
    "vars_cat = ['Pclass', 'Sex', 'Embarked']\n",
    "df = cat_to_dummy(df, columns=vars_cat, hist_dataset=hist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Pclass-3  Pclass-2  Pclass-1  \\\n",
       "0         0  22.0      1      0   7.2500         1         0         0   \n",
       "1         1  38.0      1      0  71.2833         0         0         1   \n",
       "2         1  26.0      0      0   7.9250         1         0         0   \n",
       "3         1  35.0      1      0  53.1000         0         0         1   \n",
       "4         0  35.0      0      0   8.0500         1         0         0   \n",
       "\n",
       "   Sex-male  Sex-female  Embarked-S  Embarked-C  Embarked-Q  \n",
       "0         1           0           1           0           0  \n",
       "1         0           1           0           1           0  \n",
       "2         0           1           1           0           0  \n",
       "3         0           1           1           0           0  \n",
       "4         1           0           1           0           0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Pclass-3</th>\n      <th>Pclass-2</th>\n      <th>Pclass-1</th>\n      <th>Sex-male</th>\n      <th>Sex-female</th>\n      <th>Embarked-S</th>\n      <th>Embarked-C</th>\n      <th>Embarked-Q</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "hist_dataset['cat_to_dummy'].head()"
   ]
  },
  {
   "source": [
    "# Entrenamiento y predicción de supervivientes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Para evitar poroblemas de multicolinialidad eliminamos ciertas variables dummies. Además, fusionamos las variables  'SubSp' y 'Parch' en una variable llamada 'family_size'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hist_dataset['cat_to_dummy']\n",
    "df['family_size'] = df['SibSp'] + df['Parch']\n",
    "df = df.drop(['Pclass-3', 'Sex-male', 'Embarked-C'], axis = 1)\n",
    "\n",
    "hist_dataset['Clean_Analysis'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hist_dataset['Clean_Analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Survived']\n",
    "x = df[['Age', 'SibSp', 'Parch', 'Fare', 'Pclass-1', 'Pclass-2', \n",
    "        'Sex-female','Embarked-S', 'Embarked-Q', 'family_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = [\n",
    "    (LogisticRegression(), 'reg-log'),\n",
    "    (DecisionTreeClassifier(), 'arbol-class')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    reg-log\n",
      "    Resultado de la prueba del modelo: 78.49%\n",
      "    \n",
      "    arbol-class\n",
      "    Resultado de la prueba del modelo: 75.27%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for model, name in clf:\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    out = (\n",
    "    f'''    {name}\n",
    "    Resultado de la prueba del modelo: {round(accuracy*100, 2)}%\n",
    "    '''\n",
    "    )\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "est",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}